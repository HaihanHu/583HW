{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "HM4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVitRB3K8hap",
        "colab_type": "text"
      },
      "source": [
        "# Home 4: Build a CNN for image recognition.\n",
        "\n",
        "### Name: [Haihan Hu]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMiTWO2R8hat",
        "colab_type": "text"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read, complete, and run the code.\n",
        "\n",
        "2. **Make substantial improvements** to maximize the accurcy.\n",
        "    \n",
        "3. Convert the .IPYNB file to .HTML file.\n",
        "\n",
        "    * The HTML file must contain the code and the output after execution.\n",
        "    \n",
        "    * Missing **the output after execution** will not be graded.\n",
        "    \n",
        "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
        "\n",
        "4. Submit the link to this .HTML file to Canvas.\n",
        "\n",
        "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
        "\n",
        "\n",
        "## Requirements:\n",
        "\n",
        "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
        "\n",
        "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
        "\n",
        "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
        "\n",
        "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
        "\n",
        "\n",
        "## Google Colab\n",
        "\n",
        "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
        "\n",
        "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
        "\n",
        "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
        "\n",
        "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W65DLYs8hau",
        "colab_type": "text"
      },
      "source": [
        "## 1. Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zg2mTFk8hav",
        "colab_type": "text"
      },
      "source": [
        "### 1.1. Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ-eXlAU8haw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "518404cb-f6a1-4845-e04c-254be36762b7"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "import numpy\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('shape of x_train: ' + str(x_train.shape))\n",
        "print('shape of y_train: ' + str(y_train.shape))\n",
        "print('shape of x_test: ' + str(x_test.shape))\n",
        "print('shape of y_test: ' + str(y_test.shape))\n",
        "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "shape of x_train: (50000, 32, 32, 3)\n",
            "shape of y_train: (50000, 1)\n",
            "shape of x_test: (10000, 32, 32, 3)\n",
            "shape of y_test: (10000, 1)\n",
            "number of classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUUGAMci8ha1",
        "colab_type": "text"
      },
      "source": [
        "### 1.2. One-hot encode the labels\n",
        "\n",
        "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
        "\n",
        "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
        "\n",
        "2. Apply the function to ```y_train``` and ```y_test```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNoS1gaz8ha3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9c9d317b-238c-4d22-f0f4-9286d5cf70d6"
      },
      "source": [
        "def to_one_hot(y, num_class=10):\n",
        "    results = numpy.zeros((len(y), num_class))\n",
        "    for i, y in enumerate(y):\n",
        "        results[i, y] = 1\n",
        "    return results\n",
        "\n",
        "y_train_vec = to_one_hot(y_train)\n",
        "y_test_vec = to_one_hot(y_test)\n",
        "\n",
        "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
        "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
        "\n",
        "print(y_train[0])\n",
        "print(y_train_vec[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train_vec: (50000, 10)\n",
            "Shape of y_test_vec: (10000, 10)\n",
            "[6]\n",
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNrg29f48ha6",
        "colab_type": "text"
      },
      "source": [
        "#### Remark: the outputs should be\n",
        "* Shape of y_train_vec: (50000, 10)\n",
        "* Shape of y_test_vec: (10000, 10)\n",
        "* [6]\n",
        "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEkcLuC58ha7",
        "colab_type": "text"
      },
      "source": [
        "### 1.3. Randomly partition the training set to training and validation sets\n",
        "\n",
        "Randomly partition the 50K training samples to 2 sets:\n",
        "* a training set containing 40K samples\n",
        "* a validation set containing 10K samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hseja678ha8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "16c553d1-dbca-4949-cff8-9ae1502e5e20"
      },
      "source": [
        "rand_indices = numpy.random.permutation(50000)\n",
        "train_indices = rand_indices[0:40000]\n",
        "valid_indices = rand_indices[40000:50000]\n",
        "\n",
        "x_val = x_train[valid_indices, :]\n",
        "y_val = y_train_vec[valid_indices, :]\n",
        "\n",
        "x_tr = x_train[train_indices, :]\n",
        "y_tr = y_train_vec[train_indices, :]\n",
        "\n",
        "print('Shape of x_tr: ' + str(x_tr.shape))\n",
        "print('Shape of y_tr: ' + str(y_tr.shape))\n",
        "print('Shape of x_val: ' + str(x_val.shape))\n",
        "print('Shape of y_val: ' + str(y_val.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_tr: (40000, 32, 32, 3)\n",
            "Shape of y_tr: (40000, 10)\n",
            "Shape of x_val: (10000, 32, 32, 3)\n",
            "Shape of y_val: (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXN3pEzN8hbB",
        "colab_type": "text"
      },
      "source": [
        "## 2. Build a CNN and tune its hyper-parameters\n",
        "\n",
        "1. Build a convolutional neural network model\n",
        "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
        "    * Do NOT use test data for hyper-parameter tuning!!!\n",
        "3. Try to achieve a validation accuracy as high as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScL8wX8C8hbB",
        "colab_type": "text"
      },
      "source": [
        "### Remark: \n",
        "\n",
        "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
        "* Add more layers.\n",
        "* Use regularizations, e.g., dropout.\n",
        "* Use batch normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_p2wvck8hbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b848b563-bf30-4e92-f409-e24fcbe92d2c"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_42 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_43 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 15, 15, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_44 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 13, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_45 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_48 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 558,634\n",
            "Trainable params: 556,714\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyCNYKRz8hbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "\n",
        "learning_rate = 1E-4 # to be tuned!\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77IEN6OA8hbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "97d60cc9-19ed-4a38-8ba3-841dbbe5c795"
      },
      "source": [
        "history = model.fit(x_tr, y_tr, batch_size=32, epochs=20, validation_data=(x_val, y_val))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "40000/40000 [==============================] - 16s 403us/sample - loss: 1.6815 - acc: 0.3887 - val_loss: 1.2989 - val_acc: 0.5297\n",
            "Epoch 2/20\n",
            "40000/40000 [==============================] - 14s 362us/sample - loss: 1.2959 - acc: 0.5325 - val_loss: 1.1285 - val_acc: 0.5961\n",
            "Epoch 3/20\n",
            "40000/40000 [==============================] - 14s 362us/sample - loss: 1.1409 - acc: 0.5977 - val_loss: 1.2226 - val_acc: 0.5827\n",
            "Epoch 4/20\n",
            "40000/40000 [==============================] - 14s 358us/sample - loss: 1.0308 - acc: 0.6359 - val_loss: 0.9380 - val_acc: 0.6706\n",
            "Epoch 5/20\n",
            "40000/40000 [==============================] - 14s 357us/sample - loss: 0.9454 - acc: 0.6656 - val_loss: 0.9936 - val_acc: 0.6565\n",
            "Epoch 6/20\n",
            "40000/40000 [==============================] - 14s 359us/sample - loss: 0.8805 - acc: 0.6903 - val_loss: 0.8722 - val_acc: 0.6971\n",
            "Epoch 7/20\n",
            "40000/40000 [==============================] - 14s 358us/sample - loss: 0.8230 - acc: 0.7099 - val_loss: 0.8345 - val_acc: 0.7106\n",
            "Epoch 8/20\n",
            "40000/40000 [==============================] - 14s 358us/sample - loss: 0.7732 - acc: 0.7293 - val_loss: 0.7925 - val_acc: 0.7207\n",
            "Epoch 9/20\n",
            "40000/40000 [==============================] - 14s 360us/sample - loss: 0.7270 - acc: 0.7470 - val_loss: 0.9517 - val_acc: 0.6839\n",
            "Epoch 10/20\n",
            "40000/40000 [==============================] - 14s 356us/sample - loss: 0.6821 - acc: 0.7601 - val_loss: 0.8551 - val_acc: 0.7142\n",
            "Epoch 11/20\n",
            "40000/40000 [==============================] - 14s 357us/sample - loss: 0.6462 - acc: 0.7746 - val_loss: 0.8384 - val_acc: 0.7182\n",
            "Epoch 12/20\n",
            "40000/40000 [==============================] - 14s 357us/sample - loss: 0.6084 - acc: 0.7844 - val_loss: 0.7762 - val_acc: 0.7392\n",
            "Epoch 13/20\n",
            "40000/40000 [==============================] - 14s 357us/sample - loss: 0.5775 - acc: 0.7982 - val_loss: 0.7803 - val_acc: 0.7330\n",
            "Epoch 14/20\n",
            "40000/40000 [==============================] - 14s 359us/sample - loss: 0.5515 - acc: 0.8061 - val_loss: 0.7683 - val_acc: 0.7442\n",
            "Epoch 15/20\n",
            "40000/40000 [==============================] - 14s 357us/sample - loss: 0.5260 - acc: 0.8140 - val_loss: 0.7193 - val_acc: 0.7621\n",
            "Epoch 16/20\n",
            "40000/40000 [==============================] - 14s 358us/sample - loss: 0.4998 - acc: 0.8260 - val_loss: 0.7484 - val_acc: 0.7548\n",
            "Epoch 17/20\n",
            "40000/40000 [==============================] - 14s 357us/sample - loss: 0.4765 - acc: 0.8308 - val_loss: 0.7748 - val_acc: 0.7586\n",
            "Epoch 18/20\n",
            "40000/40000 [==============================] - 14s 358us/sample - loss: 0.4510 - acc: 0.8413 - val_loss: 0.7937 - val_acc: 0.7502\n",
            "Epoch 19/20\n",
            "40000/40000 [==============================] - 14s 355us/sample - loss: 0.4323 - acc: 0.8489 - val_loss: 0.8801 - val_acc: 0.7362\n",
            "Epoch 20/20\n",
            "40000/40000 [==============================] - 14s 359us/sample - loss: 0.4119 - acc: 0.8532 - val_loss: 0.7562 - val_acc: 0.7638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byOw23h_8hbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "79c39983-d101-4dfc-b8d0-2a0abb109a35"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khzSE9eCaneS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "354f3503-dacf-455f-bb78-3a7d023bf331"
      },
      "source": [
        "score = model.evaluate(x_val, y_val, verbose=1)\n",
        "print('Training loss: {0:.4f}\\nTraining accuracy: {1:.4f}'.format(*score))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 133us/sample - loss: 0.7562 - acc: 0.7638\n",
            "Training loss: 0.7562\n",
            "Training accuracy: 0.7638\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdFoWT8_8hbQ",
        "colab_type": "text"
      },
      "source": [
        "## 3. Train (again) and evaluate the model\n",
        "\n",
        "- To this end, you have found the \"best\" hyper-parameters. \n",
        "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
        "- Evaluate your model on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbsMA3u48hbR",
        "colab_type": "text"
      },
      "source": [
        "### 3.1. Train the model on the entire training set\n",
        "\n",
        "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7L9QwbPk8hbS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<Compile your model again (using the same hyper-parameters)>\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVRLJ1Cb8hbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "<Train your model on the entire training set (50K samples)>\n",
        "<Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
        "<Do NOT use the validation_data option (because now you do not have validation data)>\n",
        "..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_IA_zfeLre7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,)\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRhJUaVE33e7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97ed5a2e-7c43-4c35-f9d0-1185503c20a7"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Activation, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv2D(32, (3, 3)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv2D(64, (3, 3)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model2.add(Conv2D(128, (3, 3), padding='same'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv2D(128, (3, 3)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(512))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_54 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_64 (Batc (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_65 (Batc (None, 15, 15, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_65 (Activation)   (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_66 (Batc (None, 13, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_67 (Batc (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_68 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_68 (Activation)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_69 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_69 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 558,634\n",
            "Trainable params: 556,714\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13QpHp063tdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b7e9d9a3-4c24-4273-e060-e84abfd0f4c5"
      },
      "source": [
        "learning_rate = 1E-4 # to be tuned!\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
        "              metrics=['acc'])\n",
        "model2.fit_generator(datagen.flow(x_train, y_train_vec, batch_size=32),\n",
        "                    steps_per_epoch=x_train.shape[0] // 32,\n",
        "                    epochs=100)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6862 - acc: 0.7662\n",
            "Epoch 91/100\n",
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6789 - acc: 0.7717\n",
            "Epoch 92/100\n",
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6781 - acc: 0.7712\n",
            "Epoch 93/100\n",
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6804 - acc: 0.7694\n",
            "Epoch 94/100\n",
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6778 - acc: 0.7715\n",
            "Epoch 95/100\n",
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6791 - acc: 0.7716\n",
            "Epoch 96/100\n",
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6728 - acc: 0.7709\n",
            "Epoch 97/100\n",
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6738 - acc: 0.7724\n",
            "Epoch 98/100\n",
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6693 - acc: 0.7710\n",
            "Epoch 99/100\n",
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6654 - acc: 0.7749\n",
            "Epoch 100/100\n",
            "1562/1562 [==============================] - 34s 22ms/step - loss: 0.6652 - acc: 0.7745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8d825e0f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ5n10BA8hbY",
        "colab_type": "text"
      },
      "source": [
        "### 3.2. Evaluate the model on the test set\n",
        "\n",
        "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUa6o51m8hbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b6eeb238-269b-4fd3-9eef-f96dc9b28252"
      },
      "source": [
        "loss_and_acc = model2.evaluate(x_test, y_test_vec)\n",
        "print('loss = ' + str(loss_and_acc[0]))\n",
        "print('accuracy = ' + str(loss_and_acc[1]))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 141us/sample - loss: 0.6463 - acc: 0.7998\n",
            "loss = 0.646286302280426\n",
            "accuracy = 0.7998\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}